<!DOCTYPE html><html class="default" lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="IE=edge"/><title>ad-llama</title><meta name="description" content="Documentation for ad-llama"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="assets/style.css"/><link rel="stylesheet" href="assets/highlight.css"/><link rel="stylesheet" href="assets/custom.css"/><script defer src="assets/main.js"></script><script async src="assets/search.js" id="tsd-search-script"></script></head><body><script>document.documentElement.dataset.theme = localStorage.getItem("tsd-theme") || "os"</script><header class="tsd-page-toolbar">
<div class="tsd-toolbar-contents container">
<div class="table-cell" id="tsd-search" data-base=".">
<div class="field"><label for="tsd-search-field" class="tsd-widget tsd-toolbar-icon search no-caption"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path d="M15.7824 13.833L12.6666 10.7177C12.5259 10.5771 12.3353 10.499 12.1353 10.499H11.6259C12.4884 9.39596 13.001 8.00859 13.001 6.49937C13.001 2.90909 10.0914 0 6.50048 0C2.90959 0 0 2.90909 0 6.49937C0 10.0896 2.90959 12.9987 6.50048 12.9987C8.00996 12.9987 9.39756 12.4863 10.5008 11.6239V12.1332C10.5008 12.3332 10.5789 12.5238 10.7195 12.6644L13.8354 15.7797C14.1292 16.0734 14.6042 16.0734 14.8948 15.7797L15.7793 14.8954C16.0731 14.6017 16.0731 14.1267 15.7824 13.833ZM6.50048 10.499C4.29094 10.499 2.50018 8.71165 2.50018 6.49937C2.50018 4.29021 4.28781 2.49976 6.50048 2.49976C8.71001 2.49976 10.5008 4.28708 10.5008 6.49937C10.5008 8.70852 8.71314 10.499 6.50048 10.499Z" fill="var(--color-text)"></path></svg></label><input type="text" id="tsd-search-field" aria-label="Search"/></div>
<div class="field">
<div id="tsd-toolbar-links"><a href="https://www.github.com/gsuuon/ad-llama">Github</a></div></div>
<ul class="results">
<li class="state loading">Preparing search index...</li>
<li class="state failure">The search index is not available</li></ul><a href="index.html" class="title">ad-llama</a></div>
<div class="table-cell" id="tsd-widgets"><a href="#" class="tsd-widget tsd-toolbar-icon menu no-caption" data-toggle="menu" aria-label="Menu"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><rect x="1" y="3" width="14" height="2" fill="var(--color-text)"></rect><rect x="1" y="7" width="14" height="2" fill="var(--color-text)"></rect><rect x="1" y="11" width="14" height="2" fill="var(--color-text)"></rect></svg></a></div></div></header>
<div class="container container-main">
<div class="col-content">
<div class="tsd-page-title">
<h2>ad-llama</h2></div>
<div class="tsd-panel tsd-typography"><a id="md:ad-llama-ðŸ¦™" class="tsd-anchor"></a><h1><a href="#md:ad-llama-ðŸ¦™">ad-llama ðŸ¦™</a></h1><p>Use tagged template literals for structured LLaMa 2 inference locally in browser via <a href="https://github.com/mlc-ai/mlc-llm">mlc-llm</a>. Runs on Chromium browsers with WebGPU support. Check <a href="./example/vite-demo">example/vite-demo</a> for an example or <a href="https://ad-llama.vercel.app/">https://ad-llama.vercel.app/</a> for a live demo.</p>
<p><a href="https://github.com/gsuuon/ad-llama/assets/6422188/54fed226-c29b-44d6-a797-cc39a4e5a5d1">https://github.com/gsuuon/ad-llama/assets/6422188/54fed226-c29b-44d6-a797-cc39a4e5a5d1</a></p>
<p>Say hi in <a href="https://discord.gg/Jag2h3fS4C">discord</a>!</p>
<a id="md:usage" class="tsd-anchor"></a><h1><a href="#md:usage">Usage</a></h1><p><code>npm install -S ad-llama</code></p>
<pre><code class="language-javascript"><span class="hl-0">import</span><span class="hl-1"> { </span><span class="hl-2">loadModel</span><span class="hl-1">, </span><span class="hl-2">ad</span><span class="hl-1"> } </span><span class="hl-0">from</span><span class="hl-1"> </span><span class="hl-3">&#39;ad-llama&#39;</span><br/><br/><span class="hl-4">const</span><span class="hl-1"> </span><span class="hl-5">loadedModel</span><span class="hl-1"> = </span><span class="hl-0">await</span><span class="hl-1"> </span><span class="hl-6">loadModel</span><span class="hl-1">(</span><span class="hl-3">&#39;Llama-2-7b-chat-hf-q4f32_1&#39;</span><span class="hl-1">)</span><br/><span class="hl-4">const</span><span class="hl-1"> </span><span class="hl-5">createContext</span><span class="hl-1"> = </span><span class="hl-6">ad</span><span class="hl-1">(</span><span class="hl-2">loadedModel</span><span class="hl-1">)</span><br/><br/><span class="hl-4">const</span><span class="hl-1"> { </span><span class="hl-5">template</span><span class="hl-1">, </span><span class="hl-5">a</span><span class="hl-1"> } = </span><span class="hl-6">createContext</span><span class="hl-1">(</span><br/><span class="hl-1">  </span><span class="hl-3">&#39;You are a dungeon master.&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-3">&#39;Create an NPC based on the Dungeons and Dragons universe.&#39;</span><br/><span class="hl-1">)</span><br/><br/><span class="hl-4">const</span><span class="hl-1"> </span><span class="hl-5">npc</span><span class="hl-1"> = </span><span class="hl-6">template</span><span class="hl-3">`{</span><br/><span class="hl-3">  &quot;description&quot;: &quot;</span><span class="hl-4">${</span><span class="hl-6">a</span><span class="hl-7">(</span><span class="hl-3">&#39;short description&#39;</span><span class="hl-7">)</span><span class="hl-4">}</span><span class="hl-3">&quot;,</span><br/><span class="hl-3">  &quot;name&quot;: &quot;</span><span class="hl-4">${</span><span class="hl-6">a</span><span class="hl-7">(</span><span class="hl-3">&#39;character name&#39;</span><span class="hl-7">)</span><span class="hl-4">}</span><span class="hl-3">&quot;,</span><br/><span class="hl-3">  &quot;weapon&quot;: &quot;</span><span class="hl-4">${</span><span class="hl-6">a</span><span class="hl-7">(</span><span class="hl-3">&#39;weapon&#39;</span><span class="hl-7">)</span><span class="hl-4">}</span><span class="hl-3">&quot;,</span><br/><span class="hl-3">  &quot;class&quot;: &quot;</span><span class="hl-4">${</span><span class="hl-6">a</span><span class="hl-7">(</span><span class="hl-3">&#39;primary class&#39;</span><span class="hl-7">)</span><span class="hl-4">}</span><span class="hl-3">&quot;</span><br/><span class="hl-3">}`</span><br/><br/><span class="hl-2">console</span><span class="hl-1">.</span><span class="hl-6">log</span><span class="hl-1">(</span><span class="hl-0">await</span><span class="hl-1"> </span><span class="hl-2">npc</span><span class="hl-1">.</span><span class="hl-6">collect</span><span class="hl-1">())</span>
</code><button>Copy</button></pre>
<p>For an example of more complicated usage including validation, retry logic and transforms check the hackernews <a href="./example/vite-demo/hn/main.ts">who&#39;s hiring example.</a></p>
<a id="md:generation" class="tsd-anchor"></a><h2><a href="#md:generation">Generation</a></h2><p>Each expression in the template literal is a new prompt and options. The prompt given for each expression is added to the system and preprompt established in context, and prior completion text (literal parts and as well as inferences) are added to the end of the LLM prompt as a partially completed assistant response (i.e. after [/INST]).</p>
<p>Each template expression can be configured independently - you can set a different temperature, token count, max length and more. Check the <code>TemplateExpressionOptions</code> type in <a href="./src/types.ts">./src/types.ts</a> for all options. <code>a</code> adds the preword to the expression prompt (by default &quot;Generate a&quot;), you can use <code>__</code> to provide a naked prompt or configure the preword as needed. If you don&#39;t need to set expression options at all, just put a string in the expression.</p>
<pre><code class="language-typescript"><span class="hl-6">template</span><span class="hl-3">`{</span><br/><span class="hl-3">  &quot;description&quot;: &quot;</span><span class="hl-4">${</span><span class="hl-6">a</span><span class="hl-7">(</span><span class="hl-3">&#39;clever description&#39;</span><span class="hl-7">, {</span><br/><span class="hl-7">    </span><span class="hl-2">maxTokens:</span><span class="hl-7"> </span><span class="hl-8">1000</span><span class="hl-7">,</span><br/><span class="hl-7">    </span><span class="hl-2">stops:</span><span class="hl-7"> [</span><span class="hl-3">&#39;</span><span class="hl-9">\n</span><span class="hl-3">&#39;</span><span class="hl-7">]</span><br/><span class="hl-7">  })</span><span class="hl-4">}</span><span class="hl-3">&quot;,</span><br/><span class="hl-3">  &quot;class&quot;: &quot;</span><span class="hl-4">${</span><span class="hl-3">&#39;a primary class for the character&#39;</span><span class="hl-4">}</span><span class="hl-3">&quot;</span><br/><span class="hl-3">}`</span>
</code><button>Copy</button></pre>
<a id="md:biased-sampling" class="tsd-anchor"></a><h3><a href="#md:biased-sampling">Biased Sampling</a></h3><p>You can modify the sampler for each expression -- this allows you to adjust the logits before sampling. You can, for example, only accept number characters for one expression, while in another avoid specific strings. The main example <a href="./example/vite-demo/src/main.ts">here</a> shows some of these options. You can build your own, but there are some helper functions exposed as <code>sample</code> to build samplers. The loaded <code>model</code> object has a <code>bias</code> field which configures the sampling - <code>avoid</code>, <code>prefer</code> allow you to adjust relative likelihood of certain tokens ids, while <code>reject</code>, <code>accept</code> change the logits to negative infinity for some ids (or all other ids).</p>
<pre><code class="language-typescript"><span class="hl-0">import</span><span class="hl-1"> { </span><span class="hl-2">sample</span><span class="hl-1"> } </span><span class="hl-0">from</span><span class="hl-1"> </span><span class="hl-3">&#39;ad-llama&#39;</span><br/><br/><span class="hl-4">const</span><span class="hl-1"> </span><span class="hl-5">model</span><span class="hl-1"> = </span><span class="hl-0">await</span><span class="hl-1"> </span><span class="hl-6">loadModel</span><span class="hl-1">(...)</span><br/><br/><span class="hl-4">const</span><span class="hl-1"> { </span><span class="hl-5">bias</span><span class="hl-1"> } = </span><span class="hl-2">model</span><br/><span class="hl-4">const</span><span class="hl-1"> { </span><span class="hl-5">oneOf</span><span class="hl-1">, </span><span class="hl-5">consistsOf</span><span class="hl-1"> } = </span><span class="hl-2">sample</span><br/><br/><span class="hl-6">template</span><span class="hl-3">`{</span><br/><span class="hl-3">  &quot;weapon&quot;: &quot;</span><span class="hl-4">${</span><span class="hl-6">a</span><span class="hl-7">(</span><span class="hl-3">&#39;special weapon&#39;</span><span class="hl-7">, {</span><br/><span class="hl-7">    </span><span class="hl-2">sampler:</span><span class="hl-7"> </span><span class="hl-2">bias</span><span class="hl-7">.</span><span class="hl-6">prefer</span><span class="hl-7">(</span><span class="hl-6">oneOf</span><span class="hl-7">([</span><span class="hl-3">&#39;Nun-chucks&#39;</span><span class="hl-7">, </span><span class="hl-3">&#39;Beam Cannon&#39;</span><span class="hl-7">]), </span><span class="hl-8">10</span><span class="hl-7">),</span><br/><span class="hl-7">  })</span><span class="hl-4">}</span><span class="hl-3">&quot;,</span><br/><span class="hl-3">  &quot;age&quot;: </span><span class="hl-4">${</span><span class="hl-6">a</span><span class="hl-7">(</span><span class="hl-3">&#39;age&#39;</span><span class="hl-7">, {</span><br/><span class="hl-7">    </span><span class="hl-2">sampler:</span><span class="hl-7"> </span><span class="hl-2">bias</span><span class="hl-7">.</span><span class="hl-6">accept</span><span class="hl-7">(</span><span class="hl-6">consistsOf</span><span class="hl-7">([</span><span class="hl-3">&#39;0&#39;</span><span class="hl-7">,</span><span class="hl-3">&#39;1&#39;</span><span class="hl-7">,</span><span class="hl-3">&#39;2&#39;</span><span class="hl-7">,</span><span class="hl-3">&#39;3&#39;</span><span class="hl-7">,</span><span class="hl-3">&#39;4&#39;</span><span class="hl-7">,</span><span class="hl-3">&#39;5&#39;</span><span class="hl-7">,</span><span class="hl-3">&#39;6&#39;</span><span class="hl-7">, </span><span class="hl-3">&#39;7&#39;</span><span class="hl-7">, </span><span class="hl-3">&#39;8&#39;</span><span class="hl-7">, </span><span class="hl-3">&#39;9&#39;</span><span class="hl-7">])),</span><br/><span class="hl-7">    </span><span class="hl-2">maxTokens:</span><span class="hl-7"> </span><span class="hl-8">3</span><br/><span class="hl-7">  })</span><span class="hl-4">}</span><span class="hl-3">,</span><br/><span class="hl-3">}`</span>
</code><button>Copy</button></pre>
<p><code>oneOf</code>, <code>consistsOf</code> try to generate relevant tokens for the provided strings in the context of the current generation expression -- as tokenizers are stateful, a simple encoding of just the provided strings won&#39;t necessarily produce tokens that would fit into the existing sequence. For example, with Llama 2&#39;s tokenizer <code>foo</code> and <code>&quot;foo&quot;</code> encode to completely different tokens:</p>
<pre><code class="language-javascript"><span class="hl-6">encode</span><span class="hl-1">(</span><span class="hl-3">&#39;&quot;foo&quot;&#39;</span><span class="hl-1">) ===Â [</span><span class="hl-8">376</span><span class="hl-1">, </span><span class="hl-8">5431</span><span class="hl-1">, </span><span class="hl-8">29908</span><span class="hl-1">]</span><br/><span class="hl-6">encode</span><span class="hl-1">(</span><span class="hl-3">&#39;foo&#39;</span><span class="hl-1">) === [</span><span class="hl-8">7953</span><span class="hl-1">]</span><br/><span class="hl-6">decode</span><span class="hl-1">([</span><span class="hl-8">5431</span><span class="hl-1">]) === </span><span class="hl-3">&#39;foo&#39;</span><br/><span class="hl-6">decode</span><span class="hl-1">([</span><span class="hl-8">7953</span><span class="hl-1">]) === </span><span class="hl-3">&#39;foo&#39;</span>
</code><button>Copy</button></pre>
<p><code>consistsOf</code> is for classes of characters - each sample in that expression generation will have the same token logits modified based on the given relevant tokens. So in <code>consistsOf([&#39;a&#39;,&#39;b&#39;])</code>, every sample will have tokens for &#39;a&#39; and &#39;b&#39; modified.</p>
<p><code>oneOf</code> is for strings - each sample has logits modified depending on the tokens which are still relevant given the already sampled tokens. For example, if we have <code>oneOf([&#39;ranger&#39;, &#39;wizard&#39;])</code> and we&#39;ve already sampled &#39;w&#39;, the only next relevant tokens would be from &#39;izard&#39;. If you want <code>oneOf</code> to stop at one of the choices, include the stop character (by default the next character after the expression), eg: <code>oneOf([&#39;ranger&quot;&#39;, &#39;wizard&quot;&#39;])</code>.</p>
<p>Even though <code>reject(oneOf([&#39;ranger&#39;, &#39;wizard&#39;]))</code> will never make it past the first token for either of the strings, giving the entire string still lets you target the correct tokens for completing those specific strings.</p>
<a id="md:validation" class="tsd-anchor"></a><h3><a href="#md:validation">Validation</a></h3><p>You can provide an expression validation function with a retry count. If validation fails, that expression will be attempted again up to retry times, after which whatever was generated is taken. You can also transform the result of the expression generation (this happens whether validation passes or not).</p>
<pre><code class="language-typescript"><span class="hl-2">validate</span><span class="hl-1">?: {</span><br/><span class="hl-1">  check?</span><span class="hl-2">:</span><span class="hl-1"> (</span><span class="hl-2">partial</span><span class="hl-1">: </span><span class="hl-10">string</span><span class="hl-1">) </span><span class="hl-4">=&gt;</span><span class="hl-1"> </span><span class="hl-2">boolean</span><br/><span class="hl-1">  </span><span class="hl-2">transform</span><span class="hl-1">?: (</span><span class="hl-2">partial</span><span class="hl-1">: </span><span class="hl-10">string</span><span class="hl-1">) </span><span class="hl-4">=&gt;</span><span class="hl-1"> </span><span class="hl-2">string</span><br/><span class="hl-1">  </span><span class="hl-2">retries</span><span class="hl-1">: </span><span class="hl-2">number</span><br/><span class="hl-1">}</span>
</code><button>Copy</button></pre>
<a id="md:vite-hmr" class="tsd-anchor"></a><h2><a href="#md:vite-hmr">Vite HMR</a></h2><p>Waiting for models to reload can be tedious, even when they&#39;re cached. ad-llama should work with vite HMR so the loaded models stay in memory. Put this in your source file to create an HMR boundary:</p>
<pre><code class="language-diff"><span class="hl-1">import { loadModel, ad, guessModelSpecFromPrebuiltId } from &#39;ad-llama&#39;</span><br/><br/><span class="hl-8">+ if (import.meta.hot) { import.meta.hot.accept() }</span><br/><br/><span class="hl-1">const loadedModel = await loadModel(guessModelSpecFromPrebuiltId(&#39;Llama-2-7b-chat-hf-q4f32_1&#39;))</span>
</code><button>Copy</button></pre>
<a id="md:build" class="tsd-anchor"></a><h1><a href="#md:build">Build</a></h1><ul>
<li>pre-reqs<ul>
<li>emcc: <a href="https://emscripten.org/docs/getting_started/downloads.html">https://emscripten.org/docs/getting_started/downloads.html</a></li>
</ul>
</li>
<li>build the tvmjs dependency first<pre><code class="language-bash"><span class="hl-6">git</span><span class="hl-1"> </span><span class="hl-3">clone</span><span class="hl-1"> </span><span class="hl-3">https://github.com/gsuuon/ad-llama.git</span><span class="hl-1"> </span><span class="hl-4">--recursive</span><br/><span class="hl-6">cd</span><span class="hl-1"> </span><span class="hl-8">3</span><span class="hl-3">rdparty/relax/web</span><br/><br/><span class="hl-11"># source ~/emsdk/emsdk_env.sh</span><br/><span class="hl-6">make</span><br/><span class="hl-6">npm</span><span class="hl-1"> </span><span class="hl-3">install</span><br/><span class="hl-6">npm</span><span class="hl-1"> </span><span class="hl-3">run</span><span class="hl-1"> </span><span class="hl-3">build</span>
</code><button>Copy</button></pre>
</li>
<li>then either <code>npm run build</code> or <code>npm run dev</code> (which watches <code>src/</code> and serves <code>public/</code>)</li>
</ul>
<a id="md:motivation" class="tsd-anchor"></a><h1><a href="#md:motivation">Motivation</a></h1><p>I was inspired by <a href="https://github.com/microsoft/guidance">guidance</a> but felt that tagged template literals were a better way to express structured inference. I also think <a href="https://github.com/ggerganov/llama.cpp/pull/1773">grammar</a> based sampling is neat, and wanted to add a way to plug something like that into MLC infrastructure.</p>
<a id="md:todos" class="tsd-anchor"></a><h1><a href="#md:todos">Todos</a></h1><ul>
<li><input disabled="" type="checkbox"> runs on Deno</li>
<li><input disabled="" type="checkbox"> can target cpu</li>
<li><input disabled="" type="checkbox"> repeatable subtemplates</li>
<li><input disabled="" type="checkbox"> template expressions can reference previously generated expressions</li>
</ul>
</div></div>
<div class="col-sidebar">
<div class="page-menu">
<div class="tsd-navigation settings">
<details class="tsd-index-accordion"><summary class="tsd-accordion-summary">
<h3><svg width="20" height="20" viewBox="0 0 24 24" fill="none"><path d="M4.93896 8.531L12 15.591L19.061 8.531L16.939 6.409L12 11.349L7.06098 6.409L4.93896 8.531Z" fill="var(--color-text)" id="icon-chevronDown"></path></svg>Settings</h3></summary>
<div class="tsd-accordion-details">
<div class="tsd-theme-toggle">
<h4 class="uppercase">Theme</h4><select id="tsd-theme"><option value="os">OS</option><option value="light">Light</option><option value="dark">Dark</option></select></div></div></details></div>
<details open class="tsd-index-accordion tsd-page-navigation"><summary class="tsd-accordion-summary">
<h3><svg width="20" height="20" viewBox="0 0 24 24" fill="none"><use href="#icon-chevronDown"></use></svg>On This Page</h3></summary>
<div class="tsd-accordion-details">
<ul>
<li>
<ul>
<li><a href="#md:ad-llama-ðŸ¦™"><span>ad-<wbr/>llama ðŸ¦™</span></a></li>
<li><a href="#md:usage"><span>Usage</span></a></li>
<li>
<ul>
<li><a href="#md:generation"><span>Generation</span></a></li>
<li>
<ul>
<li><a href="#md:biased-sampling"><span>Biased <wbr/>Sampling</span></a></li>
<li><a href="#md:validation"><span>Validation</span></a></li></ul></li>
<li><a href="#md:vite-hmr"><span>Vite HMR</span></a></li></ul></li>
<li><a href="#md:build"><span>Build</span></a></li>
<li><a href="#md:motivation"><span>Motivation</span></a></li>
<li><a href="#md:todos"><span>Todos</span></a></li></ul></li></ul></div></details></div>
<div class="site-menu">
<nav class="tsd-navigation"><a href="modules.html" class="current"><svg class="tsd-kind-icon" viewBox="0 0 24 24"><g id="icon-4"><rect fill="var(--color-icon-background)" stroke="var(--color-ts-namespace)" stroke-width="1.5" x="1" y="1" width="22" height="22" rx="6"></rect><path d="M9.33 16V7.24H10.77L13.446 14.74C13.43 14.54 13.41 14.296 13.386 14.008C13.37 13.712 13.354 13.404 13.338 13.084C13.33 12.756 13.326 12.448 13.326 12.16V7.24H14.37V16H12.93L10.266 8.5C10.282 8.692 10.298 8.936 10.314 9.232C10.33 9.52 10.342 9.828 10.35 10.156C10.366 10.476 10.374 10.784 10.374 11.08V16H9.33Z" fill="var(--color-text)"></path></g></svg><span>ad-<wbr/>llama</span></a>
<ul class="tsd-small-nested-navigation">
<li><a href="modules/_internal_.html"><svg class="tsd-kind-icon" viewBox="0 0 24 24"><use href="#icon-4"></use></svg><span>&lt;internal&gt;</span></a></li>
<li><a href="modules/sample.html"><svg class="tsd-kind-icon" viewBox="0 0 24 24"><use href="#icon-4"></use></svg><span>sample</span></a></li>
<li><a href="modules/validate.html"><svg class="tsd-kind-icon" viewBox="0 0 24 24"><use href="#icon-4"></use></svg><span>validate</span></a></li>
<li><a href="enums/TargetDevice.html"><svg class="tsd-kind-icon" viewBox="0 0 24 24"><g id="icon-8"><rect fill="var(--color-icon-background)" stroke="var(--color-ts-enum)" stroke-width="1.5" x="1" y="1" width="22" height="22" rx="6"></rect><path d="M9.45 16V7.24H14.49V8.224H10.518V10.936H14.07V11.908H10.518V15.016H14.49V16H9.45Z" fill="var(--color-text)"></path></g></svg><span>Target<wbr/>Device</span></a></li>
<li><a href="functions/ad.html"><svg class="tsd-kind-icon" viewBox="0 0 24 24"><g id="icon-64"><rect fill="var(--color-icon-background)" stroke="var(--color-ts-function)" stroke-width="1.5" x="1" y="1" width="22" height="22" rx="6"></rect><path d="M9.39 16V7.24H14.55V8.224H10.446V11.128H14.238V12.112H10.47V16H9.39Z" fill="var(--color-text)"></path></g></svg><span>ad</span></a></li>
<li><a href="functions/loadModel.html"><svg class="tsd-kind-icon" viewBox="0 0 24 24"><use href="#icon-64"></use></svg><span>load<wbr/>Model</span></a></li></ul></nav></div></div></div>
<div class="tsd-generator">
<p>Generated using <a href="https://typedoc.org/" target="_blank">TypeDoc</a></p></div>
<div class="overlay"></div></body></html>